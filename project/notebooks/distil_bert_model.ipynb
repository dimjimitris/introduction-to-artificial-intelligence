{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vbv5y6kwAFu",
        "outputId": "a92f91f8-7a8b-4027-a96d-b266d2ca36ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXE--Yib5GyQ",
        "outputId": "c026479d-aead-434a-c414-428808847788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.12.1)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from emoji) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.31.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.40)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji langdetect transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsG4xHOkgvbj",
        "outputId": "48b80b69-a277-47f3-cf05-3323797ba96f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# %% Import libraries\n",
        "import bz2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import emoji\n",
        "from nltk.corpus import stopwords\n",
        "from langdetect import detect, DetectorFactory\n",
        "from langdetect.lang_detect_exception import LangDetectException\n",
        "import pickle\n",
        "import os\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Check if GPU is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Ensure consistent results with langdetect\n",
        "DetectorFactory.seed = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESze5mjMgxD9",
        "outputId": "d176385e-b56b-435c-80ec-af7821983cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   label                                               text\n",
            "0      1  stuning even nongamer sound track beautiful pa...\n",
            "1      1  best soundtrack ever anything im reading lot r...\n",
            "2      1  amazing soundtrack favorite music time hands i...\n",
            "3      1  excellent soundtrack truly like soundtrack enj...\n",
            "4      1  remember pull jaw floor hearing youve played g...\n"
          ]
        }
      ],
      "source": [
        "# %% Load and pre-process dataset\n",
        "def preprocess_data(sample_size):\n",
        "    # Load and balance the dataset\n",
        "    file_path = r'/content/drive/MyDrive/Colab Notebooks/AmazonReviews/train.ft.txt.bz2'\n",
        "    positive_reviews = []\n",
        "    negative_reviews = []\n",
        "\n",
        "    with bz2.open(file_path, 'rt', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            label, text = line.split(' ', 1)\n",
        "            label = int(label[-1])\n",
        "            if label == 1 and len(negative_reviews) < sample_size // 2:\n",
        "                negative_reviews.append([label, text])\n",
        "            elif label == 2 and len(positive_reviews) < sample_size // 2:\n",
        "                positive_reviews.append([label, text])\n",
        "            if len(positive_reviews) == sample_size // 2 and len(negative_reviews) == sample_size // 2:\n",
        "                break\n",
        "\n",
        "    # Combine positive and negative reviews\n",
        "    data = positive_reviews + negative_reviews\n",
        "    df = pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "    # Function to detect language\n",
        "    def detect_language(text):\n",
        "        try:\n",
        "            return detect(text)\n",
        "        except LangDetectException:\n",
        "            return \"unknown\"\n",
        "\n",
        "    # Detect language\n",
        "    df['language'] = df['text'].apply(detect_language)\n",
        "\n",
        "    # Filter out non-English reviews\n",
        "    df = df[df['language'] == 'en']\n",
        "    df = df.drop(columns=['language'])\n",
        "\n",
        "    # Initialize stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def clean_text(text):\n",
        "        # Replace emojis with descriptive words\n",
        "        text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "        # Remove HTML tags\n",
        "        text = re.sub(r'<.*?>', '', text)\n",
        "        # Remove URLs\n",
        "        text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
        "        # Remove hashtags\n",
        "        text = re.sub(r'#\\w+', '', text)\n",
        "        # Remove special characters and digits\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        # Remove stopwords\n",
        "        text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "        return text\n",
        "\n",
        "    # Apply text cleaning to the 'text' column\n",
        "    df['text'] = df['text'].apply(clean_text)\n",
        "\n",
        "    df['label'] = df['label'] - 1\n",
        "\n",
        "    return df\n",
        "\n",
        "SAMPLE_SIZE = 20_000\n",
        "processed_data_file = r'/content/drive/MyDrive/Colab Notebooks/AmazonReviews/processed_data.pkl'\n",
        "\n",
        "if os.path.exists(processed_data_file):\n",
        "    with open(processed_data_file, 'rb') as file:\n",
        "        df = pickle.load(file)\n",
        "else:\n",
        "    df = preprocess_data(SAMPLE_SIZE)\n",
        "    with open(processed_data_file, 'wb') as file:\n",
        "        pickle.dump(df, file)\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvpWcm4B8ZQw"
      },
      "outputs": [],
      "source": [
        "# %% Tokenization with DistilBERT\n",
        "tokenized_data_file = r'/content/drive/MyDrive/Colab Notebooks/AmazonReviews/tokenized_data.pkl'\n",
        "\n",
        "if os.path.exists(tokenized_data_file):\n",
        "    with open(tokenized_data_file, 'rb') as file:\n",
        "        train_encodings, test_encodings, y_train, y_test = pickle.load(file)\n",
        "else:\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "    # Tokenize the texts in the dataset\n",
        "    def tokenize_texts(texts, max_length=512):\n",
        "        return tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
        "\n",
        "    # Split the data into training and test sets\n",
        "    labels = df['label'].values\n",
        "    texts = df['text'].tolist()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Tokenize the datasets\n",
        "    train_encodings = tokenize_texts(X_train)\n",
        "    test_encodings = tokenize_texts(X_test)\n",
        "\n",
        "    # Save tokenized data\n",
        "    with open(tokenized_data_file, 'wb') as file:\n",
        "        pickle.dump((train_encodings, test_encodings, y_train, y_test), file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77vRGAc5lv8f"
      },
      "outputs": [],
      "source": [
        "# %% Custom Dataset Class\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create instances of the custom dataset\n",
        "train_dataset = CustomDataset(train_encodings, y_train)\n",
        "eval_dataset = CustomDataset(test_encodings, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "bDBVczAj8kje",
        "outputId": "183fa026-89ae-448e-b533-eb25c096d41b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-6-99b078ff57ec>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2994' max='2994' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2994/2994 15:18, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.440000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.313500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.211500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.192400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.095900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-99b078ff57ec>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-6-99b078ff57ec>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-6-99b078ff57ec>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-6-99b078ff57ec>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-6-99b078ff57ec>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        }
      ],
      "source": [
        "# %% Define and train DistilBERT model\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(device)\n",
        "model_state_file = r'/content/drive/MyDrive/Colab Notebooks/AmazonReviews/distilbert_model_state.pth'\n",
        "\n",
        "if os.path.exists(model_state_file):\n",
        "    print(\"Loading fine-tuned model from state file...\")\n",
        "    model.load_state_dict(torch.load(model_state_file))\n",
        "else:\n",
        "    # Define training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=64,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./logs',\n",
        "    )\n",
        "\n",
        "    # Define Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(model.state_dict(), model_state_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2n625iPMh2Fb",
        "outputId": "4853b915-5db3-4c6a-8f7f-b695e5c07d2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-99b078ff57ec>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DistilBERT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.91      1991\n",
            "           1       0.91      0.90      0.91      2000\n",
            "\n",
            "    accuracy                           0.91      3991\n",
            "   macro avg       0.91      0.91      0.91      3991\n",
            "weighted avg       0.91      0.91      0.91      3991\n",
            "\n",
            "[[1816  175]\n",
            " [ 202 1798]]\n"
          ]
        }
      ],
      "source": [
        "# %% Evaluate the fine-tuned DistilBERT model\n",
        "trainer.evaluate()\n",
        "\n",
        "# Get predictions\n",
        "predictions = trainer.predict(eval_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Evaluation metrics\n",
        "print(\"DistilBERT:\")\n",
        "print(classification_report(y_test, preds))\n",
        "print(confusion_matrix(y_test, preds))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}